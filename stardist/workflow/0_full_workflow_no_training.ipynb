{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-12T15:25:41.516698Z",
     "start_time": "2024-06-12T15:25:37.674256600Z"
    }
   },
   "outputs": [],
   "source": [
    "from tifffile import imread\n",
    "from functions import *\n",
    "import json\n",
    "import geojson\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fbbe1e6f83c2e13d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "WSI_path = r'\\\\10.99.68.54\\Digital pathology image lib\\HubMap Skin TMC project\\CellViT\\inference_pilot'\n",
    "model_path = r'\\\\10.162.80.16\\Andre_expansion\\data\\Stardist\\PDAC model\\models\\lea_model'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T15:25:41.538698500Z",
     "start_time": "2024-06-12T15:25:41.516698Z"
    }
   },
   "id": "bb455a5311df807c",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "base_model.py (149): output path for model already exists, files may be overwritten: \\\\10.162.80.16\\Andre_expansion\\data\\Stardist\\PDAC model\\models\\lea_model\\offshoot_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default values: prob_thresh=0.5, nms_thresh=0.4.\n",
      "Overriding defaults: Thresholds(prob=0.4872387821889486, nms=0.3) \n"
     ]
    }
   ],
   "source": [
    "# WSIs = [os.path.join(WSI_path, f) for f in os.listdir(WSI_path) if f.endswith('.ndpi')]  # change if using tif or czi file\n",
    "WSIs = [os.path.join(WSI_path, f) for f in os.listdir(WSI_path) if f.endswith('.svs')]  # change if using tif or czi file\n",
    "model = load_model(model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T15:25:43.211106300Z",
     "start_time": "2024-06-12T15:25:41.533698200Z"
    }
   },
   "id": "82b1833b546b785f",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default values: prob_thresh=0.5, nms_thresh=0.4.\n",
      "Overriding defaults: Thresholds(prob=0.4872387821889486, nms=0.3) \n",
      "\n",
      "\\\\10.99.68.54\\Digital pathology image lib\\HubMap Skin TMC project\\CellViT\\inference_pilot\\StarDist_2_23_24\\json\n"
     ]
    }
   ],
   "source": [
    "model = load_model(model_path)\n",
    "date = '2_23_24'\n",
    "\n",
    "out_pth = os.path.join(WSI_path, f'StarDist_{date}')\n",
    "if not os.path.exists(out_pth):\n",
    "    os.mkdir(out_pth)\n",
    "\n",
    "out_pth_json = os.path.join(out_pth, 'json')\n",
    "out_pth_tif = os.path.join(out_pth, 'tif')\n",
    "print(out_pth_json)\n",
    "\n",
    "if not os.path.exists(out_pth_json):\n",
    "    os.mkdir(out_pth_json)\n",
    "\n",
    "if not os.path.exists(out_pth_json):\n",
    "    os.mkdir(out_pth_json)\n",
    "\n",
    "if not os.path.exists(out_pth_tif):\n",
    "    os.mkdir(out_pth_tif)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T15:26:37.652527900Z",
     "start_time": "2024-06-12T15:26:37.409523500Z"
    }
   },
   "id": "b6afd9551a53f7e",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting TCGA-V5-A7RE-11A-01-TS1.57401526-EF9E-49AC-8FF6-B4F9652311CE.svs\n",
      "effective: block_size=(4096, 4096, 3), min_overlap=(128, 128, 0), context=(128, 128, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:26<00:00,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving json...\n",
      "Finished TCGA-V5-A7RE-11A-01-TS1.57401526-EF9E-49AC-8FF6-B4F9652311C.json\n"
     ]
    }
   ],
   "source": [
    "# Segment all WSIs -- takes about 2-5 minutes per whole slide image to segment, about 3 minutes to save geojson file\n",
    "for img_pth in WSIs:\n",
    "    try:\n",
    "        name = os.path.basename(img_pth)\n",
    "\n",
    "        if not os.path.exists(os.path.join(out_pth_json, (name[:-5] + '.json'))):\n",
    "            print(f'Starting {name}')\n",
    "\n",
    "            img = imread(img_pth)\n",
    "            img = img/255  # normalization used to train model\n",
    "            _, polys = model.predict_instances_big(img, axes='YXC', block_size=4096, min_overlap=128, context=128, n_tiles=(4,4,1))\n",
    "\n",
    "            print('Saving json...')\n",
    "            save_json_from_WSI_pred(polys, out_pth_json, name)\n",
    "\n",
    "            # tif file is like 3 GB usually, so only uncomment next part if you are ok with that\n",
    "            #print('Saving tif...')\n",
    "            #imwrite(os.path.join(out_pth_tif, name[:-5] + '.tif'), labels)\n",
    "        else:\n",
    "            print(f'Skipping {name}')\n",
    "    except:\n",
    "        print(f'skipping {img_pth}, probably bc its too big...')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T15:27:56.286811900Z",
     "start_time": "2024-06-12T15:26:45.663334100Z"
    }
   },
   "id": "f2ff82617fdea54",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\\\\\\\10.99.68.54\\\\Digital pathology image lib\\\\HubMap Skin TMC project\\\\CellViT\\\\inference_pilot\\\\StarDist_2_23_24\\\\json\\\\TCGA-V5-A7RE-11A-01-TS1.57401526-EF9E-49AC-8FF6-B4F9652311C.json']\n"
     ]
    }
   ],
   "source": [
    "json_pth_list = sorted([os.path.join(out_pth_json,file) for file in os.listdir(out_pth_json) if file.endswith(\".json\")])\n",
    "print(json_pth_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T15:27:56.309821Z",
     "start_time": "2024-06-12T15:27:56.289617700Z"
    }
   },
   "id": "5242332a8dfa1dfb",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "make geojson file to load over ndpi file in qupath"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b89ce3361070ae06"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 1\n",
      "TCGA-V5-A7RE-11A-01-TS1.57401526-EF9E-49AC-8FF6-B4F9652311C.json\n",
      "Finished \\\\10.99.68.54\\Digital pathology image lib\\HubMap Skin TMC project\\CellViT\\inference_pilot\\StarDist_2_23_24\\TCGA-V5-A7RE-11A-01-TS1.57401526-EF9E-49AC-8FF6-B4F9652311C.geojson\n"
     ]
    }
   ],
   "source": [
    "for p, file in enumerate([json_pth_list[0]]):\n",
    "    nm = file.split('\\\\')[-1]\n",
    "    new_fn = os.path.join(out_pth, nm[:-5] + '.geojson')\n",
    "    print(f'{p} / {len(json_pth_list)}')\n",
    "    print(nm)\n",
    "    \n",
    "    if not os.path.exists(new_fn):\n",
    "    \n",
    "        segmentation_data = json.load(open(file))\n",
    "        \n",
    "        data_list = format_seg_data(segmentation_data, ds_amt)\n",
    "    \n",
    "        GEOdata = []\n",
    "        \n",
    "        for j, (centroid, contour) in enumerate(data_list):\n",
    "            \n",
    "            #if j == 100000:\n",
    "            #    break\n",
    "            \n",
    "            centroid = [centroid[0] + 0, centroid[1] + 0]\n",
    "            # xy coordinates are swapped, so I reverse them here with xy[::-1]\n",
    "            # note: add 1 to coords to fix 0 indexing vs 1 index offset\n",
    "            contour = [[coord+0 for coord in xy[::-1]] for xy in contour]  # Convert coordinates to integers\n",
    "            contour.append(contour[0]) # stardist doesn't close the circle, needed for qupath\n",
    "        \n",
    "            # Create a new dictionary for each contour\n",
    "            dict_data = {\n",
    "                \"type\": \"Feature\",\n",
    "                \"id\": \"PathCellObject\",\n",
    "                \"geometry\": {\n",
    "                    \"type\": \"Polygon\",\n",
    "                    \"coordinates\": [contour]\n",
    "                },\n",
    "                \"properties\": {\n",
    "                    'objectType': 'annotation',\n",
    "                    'classification': {'name': 'Nuclei', 'color': [97, 214, 59]}\n",
    "                }\n",
    "            }\n",
    "        \n",
    "            GEOdata.append(dict_data)\n",
    "        \n",
    "        with open(new_fn,'w') as outfile:\n",
    "            geojson.dump(GEOdata,outfile)\n",
    "        print('Finished',new_fn)\n",
    "    \n",
    "    else:\n",
    "        print(f'skipping {new_fn}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T15:29:38.098968400Z",
     "start_time": "2024-06-12T15:28:35.091112Z"
    }
   },
   "id": "dfb0a263a657ef32",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "Make pickle file with nuclear features output"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae36a3bee7e3eb70"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from analysis_functions import *"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T15:47:46.961291100Z",
     "start_time": "2024-06-12T15:47:46.896287400Z"
    }
   },
   "id": "63d2a121eb5e21ad",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\\10.99.68.54\\Digital pathology image lib\\HubMap Skin TMC project\\CellViT\\inference_pilot\\StarDist_2_23_24\\json\\nuclei_features_pkls\n"
     ]
    }
   ],
   "source": [
    "pkl_pth = os.path.join(out_pth_json,'nuclei_features_pkls')\n",
    "if not os.path.exists(pkl_pth): os.mkdir(pkl_pth)\n",
    "print(pkl_pth)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T15:52:44.787909500Z",
     "start_time": "2024-06-12T15:52:44.768909100Z"
    }
   },
   "id": "afbb6c6a0a7628d6",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\\10.99.68.54\\Digital pathology image lib\\HubMap Skin TMC project\\CellViT\\inference_pilot\\StarDist_2_23_24\\json\\nuclei_features_pkls\\TCGA-V5-A7RE-11A-01-TS1.pkl\n",
      "\\\\10.99.68.54\\Digital pathology image lib\\HubMap Skin TMC project\\CellViT\\inference_pilot\\TCGA-V5-A7RE-11A-01-TS1.57401526-EF9E-49AC-8FF6-B4F9652311CE.svs\n",
      "\\\\10.99.68.54\\Digital pathology image lib\\HubMap Skin TMC project\\CellViT\\inference_pilot\\StarDist_2_23_24\\json\\TCGA-V5-A7RE-11A-01-TS1.57401526-EF9E-49AC-8FF6-B4F9652311C.json\n",
      "centroid passed: [22, 10768]\n",
      "centroid passed: [28, 10060]\n",
      "centroid passed: [8, 10706]\n",
      "centroid passed: [26, 10722]\n",
      "centroid passed: [4, 9946]\n",
      "centroid passed: [6, 10068]\n",
      "centroid passed: [26, 10222]\n",
      "centroid passed: [12, 10686]\n",
      "centroid passed: [20, 10096]\n",
      "centroid passed: [10, 10782]\n",
      "centroid passed: [10, 10576]\n",
      "centroid passed: [14, 10298]\n",
      "centroid passed: [22, 10916]\n",
      "centroid passed: [26, 10838]\n",
      "centroid passed: [10, 11020]\n",
      "centroid passed: [12, 11098]\n",
      "centroid passed: [20, 10848]\n"
     ]
    }
   ],
   "source": [
    "for i, json_f_name in enumerate(json_pth_list):\n",
    "    \n",
    "    nm = json_f_name.split('\\\\')[-1].split('.')[0]\n",
    "    \n",
    "    outnm = os.path.join(pkl_pth, f'{nm}.pkl')\n",
    "    print(outnm)\n",
    "    \n",
    "    if not os.path.exists(outnm):\n",
    "        \n",
    "        HE_20x_WSI = imread(WSIs[i])\n",
    "        \n",
    "        print(WSIs[i])\n",
    "        print(json_f_name)\n",
    "        \n",
    "        try:\n",
    "            segmentation_data = json.load(open(json_f_name))\n",
    "        except:\n",
    "            print(f'error reading json... Skipping {json_f_name}')\n",
    "            continue\n",
    "    \n",
    "        centroids = [nuc['centroid'][0] for nuc in segmentation_data]\n",
    "        contours = [nuc['contour'] for nuc in segmentation_data]\n",
    "        contours_fixed = fix_contours(contours)\n",
    "        \n",
    "        # part of code below gets rgb intensity values within each nucleus contour, to do this efficiently, it crops\n",
    "        # a small part of the image for each nucleus. The offset variable determines how big the crop is. 30 should \n",
    "        # be fine for 20x images with normal/large sized nuclei but you can play with it yourself if you want\n",
    "        # it will skip nuclei that are by the edge and thus can't crop that image, it calls these intensities -1\n",
    "        \n",
    "        offset = 30  # radius of image that gets cropped from WSI, used for getting rgb intensity average inside nuc contour\n",
    "        \n",
    "        centroids_np = np.array(centroids)  # for other formatting\n",
    "        contours_np = np.array(contours)\n",
    "        \n",
    "        r_avg_list = []\n",
    "        g_avg_list = []\n",
    "        b_avg_list = []\n",
    "        \n",
    "        areas = []\n",
    "        perimeters = []\n",
    "        circularities = []\n",
    "        aspect_ratios = []\n",
    "        image_ids = []\n",
    "        classes = []\n",
    "        \n",
    "        compactness_a, eccentricity_a, euler_number_a, extent_a, form_factor_a, maximum_radius_a, mean_radius_a, median_radius_a, minor_axis_length_a, major_axis_length_a, orientation_degrees_a = [], [], [], [], [], [], [], [], [], [], []\n",
    "        \n",
    "        np_centroids = np.array(centroids)\n",
    "        \n",
    "        for j in range(len(contours_fixed)):\n",
    "            #break\n",
    "            \n",
    "            centroid = centroids[j]\n",
    "            # print(f'centroid: {centroid}')\n",
    "            contour_raw = copy.copy(contours_fixed[j])  # used for rgb intensities\n",
    "             \n",
    "            # get rbg intensity averages\n",
    "            r_avg, g_avg, b_avg = get_rbg_avg(centroid, contour_raw, offset, HE_20x_WSI)\n",
    "            # print(r_avg, g_avg, b_avg)\n",
    "            \n",
    "            r_avg_list.append(r_avg)\n",
    "            g_avg_list.append(g_avg)\n",
    "            b_avg_list.append(b_avg)\n",
    "            \n",
    "            contour = contours_np[j][0].transpose()  # used for other stuff, too lazy to make formatting the same\n",
    "            area = cntarea(contour)\n",
    "            perimeter = cntperi(contour)\n",
    "            circularity = 4 * np.pi * area / perimeter ** 2\n",
    "            MA = cntMA(contour)\n",
    "            [MA, ma, orientation] = MA\n",
    "            aspect_ratio = MA / ma\n",
    "            #center_x = centroid[0]\n",
    "            #center_y = centroid[1]\n",
    "            \n",
    "            cent_x = np_centroids[j,0]\n",
    "            cent_y = np_centroids[j,1]\n",
    "            \n",
    "            #compactness and form_factor are stupid because they are basically same as circularity, maybe extent too\n",
    "            \n",
    "            compactness = perimeter ** 2 / area\n",
    "            eccentricity = np.sqrt(1 - (ma / MA) ** 2)\n",
    "            extent = area / (MA * ma)\n",
    "            form_factor = (perimeter ** 2) / (4 * np.pi * area)\n",
    "            major_axis_length = MA\n",
    "            maximum_radius = np.max(np.linalg.norm(contour - centroid, axis=1))\n",
    "            mean_radius = np.mean(np.linalg.norm(contour - centroid, axis=1))\n",
    "            median_radius = np.median(np.linalg.norm(contour - centroid, axis=1))\n",
    "            minor_axis_length = ma\n",
    "            orientation_degrees = np.degrees(orientation)\n",
    "            \n",
    "            areas.append(area)\n",
    "            perimeters.append(perimeter)\n",
    "            circularities.append(circularity)\n",
    "            aspect_ratios.append(aspect_ratio)\n",
    "    \n",
    "            # additional features\n",
    "            compactness_a.append(compactness)\n",
    "            eccentricity_a.append(eccentricity)\n",
    "            extent_a.append(extent)\n",
    "            form_factor_a.append(form_factor)\n",
    "            maximum_radius_a.append(maximum_radius)\n",
    "            mean_radius_a.append(mean_radius)\n",
    "            median_radius_a.append(median_radius)\n",
    "            minor_axis_length_a.append(minor_axis_length)\n",
    "            major_axis_length_a.append(major_axis_length)\n",
    "            orientation_degrees_a.append(orientation_degrees)\n",
    "            \n",
    "            \n",
    "        # exit loop\n",
    "            \n",
    "        dat = {\n",
    "            'Centroid_x': np_centroids[:,1],\n",
    "            'Centroid_y': np_centroids[:,0],\n",
    "            'Area': areas,\n",
    "            'Perimeter': perimeters,\n",
    "            'Circularity': circularities,\n",
    "            'Aspect Ratio': aspect_ratios,\n",
    "            'compactness' : compactness_a,\n",
    "            'eccentricity' : eccentricity_a,\n",
    "            'extent' : extent_a,\n",
    "            'form_factor' : form_factor_a,\n",
    "            'maximum_radius' : maximum_radius_a,\n",
    "            'mean_radius' : mean_radius_a,\n",
    "            'median_radius' : median_radius_a,\n",
    "            'minor_axis_length' : minor_axis_length_a,\n",
    "            'major_axis_length' : major_axis_length_a,\n",
    "            'orientation_degrees' : orientation_degrees_a,\n",
    "            'r_mean_intensity' : r_avg_list,\n",
    "            'g_mean_intensity' : g_avg_list,\n",
    "            'b_mean_intensity' : b_avg_list,\n",
    "            #'slide_num': nm[-4:]  # fix this for your own needs, this gets slide number for my monkey fetus\n",
    "        }\n",
    "    \n",
    "        df = pd.DataFrame(dat).astype(np.float32)  # save a little space with float16 type -> Edit 2 months later, this did not save time.\n",
    "        \n",
    "        df.to_pickle(outnm)\n",
    "        #break\n",
    "    else:\n",
    "        print('skipping')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T15:53:02.582291500Z",
     "start_time": "2024-06-12T15:52:57.931179600Z"
    }
   },
   "id": "3cea38f9a59b451c",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\\10.99.68.54\\Digital pathology image lib\\HubMap Skin TMC project\\CellViT\\inference_pilot\\StarDist_2_23_24\\json\\nuclei_features_pkls\\nuclei_features_mats\n"
     ]
    }
   ],
   "source": [
    "mat_pth = os.path.join(pkl_pth,'nuclei_features_mats')\n",
    "if not os.path.exists(mat_pth): os.mkdir(mat_pth)\n",
    "print(mat_pth)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T15:54:00.324174Z",
     "start_time": "2024-06-12T15:54:00.313173100Z"
    }
   },
   "id": "5e9b68cf9619a5cd",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pickle\n",
    "from scipy.io import savemat"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T15:57:44.821307100Z",
     "start_time": "2024-06-12T15:57:44.807307300Z"
    }
   },
   "id": "6bca067470fb0b78",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving: \\\\10.99.68.54\\Digital pathology image lib\\HubMap Skin TMC project\\CellViT\\inference_pilot\\StarDist_2_23_24\\json\\nuclei_features_pkls\\nuclei_features_mats\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '\\\\\\\\10.99.68.54\\\\Digital pathology image lib\\\\HubMap Skin TMC project\\\\CellViT\\\\inference_pilot\\\\StarDist_2_23_24\\\\json\\\\nuclei_features_pkls\\\\nuclei_features_mats'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mPermissionError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[29], line 9\u001B[0m\n\u001B[0;32m      5\u001B[0m outnm \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(mat_pth,os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mbasename(dfnm))\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSaving: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(dfnm))\n\u001B[1;32m----> 9\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdfnm\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m     10\u001B[0m     df \u001B[38;5;241m=\u001B[39m pickle\u001B[38;5;241m.\u001B[39mload(f)\n\u001B[0;32m     12\u001B[0m col_names \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mtolist()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\monkey_nuc_segment_v6\\lib\\site-packages\\IPython\\core\\interactiveshell.py:284\u001B[0m, in \u001B[0;36m_modified_open\u001B[1;34m(file, *args, **kwargs)\u001B[0m\n\u001B[0;32m    277\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n\u001B[0;32m    278\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    279\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    280\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    281\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    282\u001B[0m     )\n\u001B[1;32m--> 284\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m io_open(file, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "\u001B[1;31mPermissionError\u001B[0m: [Errno 13] Permission denied: '\\\\\\\\10.99.68.54\\\\Digital pathology image lib\\\\HubMap Skin TMC project\\\\CellViT\\\\inference_pilot\\\\StarDist_2_23_24\\\\json\\\\nuclei_features_pkls\\\\nuclei_features_mats'"
     ]
    }
   ],
   "source": [
    "# I am pretty sure that this will work but I couldn't test it on the folder I was working with bc I don't have permission but just ask chatGPT if it doesn't work\n",
    "\n",
    "dfs = [os.path.join(pkl_pth,f) for f in os.listdir(pkl_pth)]\n",
    "\n",
    "for dfnm in dfs:\n",
    "    \n",
    "    outnm = os.path.join(mat_pth,os.path.basename(dfnm))\n",
    "    \n",
    "    print(\"Saving: {}\".format(dfnm))\n",
    "        \n",
    "    with open(os.path.join(dfnm), 'rb') as f:\n",
    "        df = pickle.load(f)\n",
    "\n",
    "    col_names = df.columns.tolist()\n",
    "    df = [_ for _ in df.to_numpy()]\n",
    "    df = np.array(df)\n",
    "    \n",
    "    savemat(outnm, {'features':df, 'feature_names':col_names})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T15:58:36.284864900Z",
     "start_time": "2024-06-12T15:58:36.253245Z"
    }
   },
   "id": "53f765debd60206f",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5bd39cb3ea9369f8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
